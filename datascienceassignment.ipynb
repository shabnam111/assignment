{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBLEM STATEMENT\n",
    "\n",
    "Dataset (attached with the task): The data contains a pair of paragraphs. These text paragraphs are randomly sampled from a raw dataset. Each pair of sentences may or may not be semantically similar. The candidate is to predict a value between 0-1 indicating the similarity between the pair of text paras. A sample of a similar dataset will be used as test data, therefore it’s crucial to the model solution using provided dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part A\n",
    "Build an algorithm/model that can quantify the degree of similarity between the two text-based on Semantic similarity. Semantic Textual Similarity (STS) assesses the degree to which two sentences are semantically equivalent to each other.\n",
    "1 means highly similar, 0 means highly dissimilar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT SOME LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shabnam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading word_tokenize: Package 'word_tokenize' not\n",
      "[nltk_data]     found in index\n",
      "[nltk_data] Downloading package wordnet to /Users/shabnam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download(\"word_tokenize\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "# importing libraries \n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,LancasterStemmer\n",
    "#from contractions import fix \n",
    "#from unidecode import unidecode\n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV, StratifiedKFold\n",
    "import pandas\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from gensim.models import Word2Vec,doc2vec\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.svm import SVC,SVR\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import gensim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READ DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing the number of ...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested over drug find rap mogul mar...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn-out worries robinson england coach...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearts of oak 3-2 cotonsport hearts of oak set...</td>\n",
       "      <td>redford s vision of sundance despite sporting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
       "      <td>mauresmo opens with victory in la amelie maure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  broadband challenges tv viewing the number of ...   \n",
       "1  rap boss arrested over drug find rap mogul mar...   \n",
       "2  player burn-out worries robinson england coach...   \n",
       "3  hearts of oak 3-2 cotonsport hearts of oak set...   \n",
       "4  sir paul rocks super bowl crowds sir paul mcca...   \n",
       "\n",
       "                                               text2  \n",
       "0  gardener wins double in glasgow britain s jaso...  \n",
       "1  amnesty chief laments war failure the lack of ...  \n",
       "2  hanks greeted at wintry premiere hollywood sta...  \n",
       "3  redford s vision of sundance despite sporting ...  \n",
       "4  mauresmo opens with victory in la amelie maure...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='/Users/shabnam/Downloads/DataNeuron_DataScience_Task1/untitled folder/DataNeuron_Text_Similarity.csv'\n",
    "df=pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text1    0\n",
       "text2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRE-PROCESSING DATASET\n",
    "Convert phrases like won't to will not using function decontracted() below\n",
    "Remove Stopwords.\n",
    "Remove any special symbols and lower case all words\n",
    "lemmatizing words using WordNetLemmatizer define in function word_tokenizer below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontract(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [01:52<00:00, 26.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Combining all the above stundents \n",
    "\n",
    "preprocessed_text1 = []\n",
    "\n",
    "# tqdm is for printing the status bar\n",
    "\n",
    "for sentance in tqdm(df['text1'].values):\n",
    "    sent = decontract(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "\n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords.words('english'))\n",
    "    preprocessed_text1.append(sent.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[broadband, challenges, tv, viewing, the, numb...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[rap, boss, arrested, over, drug, find, rap, m...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[player, burn-out, worries, robinson, england,...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hearts, of, oak, 3-2, cotonsport, hearts, of,...</td>\n",
       "      <td>redford s vision of sundance despite sporting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[sir, paul, rocks, super, bowl, crowds, sir, p...</td>\n",
       "      <td>mauresmo opens with victory in la amelie maure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>[uk, directors, guild, nominees, named, martin...</td>\n",
       "      <td>steel firm  to cut  45 000 jobs mittal steel  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>[u2, to, play, at, grammy, awards, show, irish...</td>\n",
       "      <td>israel looks to us for bank chief israel has a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>[pountney, handed, ban, and, fine, northampton...</td>\n",
       "      <td>india and iran in gas export deal india has si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>[belle, named, best, scottish, band, belle, &amp;,...</td>\n",
       "      <td>mido makes third apology ahmed  mido  hossam h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>[criminal, probe, on, citigroup, deals, trader...</td>\n",
       "      <td>former ni minister scott dies former northern ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text1  \\\n",
       "0     [broadband, challenges, tv, viewing, the, numb...   \n",
       "1     [rap, boss, arrested, over, drug, find, rap, m...   \n",
       "2     [player, burn-out, worries, robinson, england,...   \n",
       "3     [hearts, of, oak, 3-2, cotonsport, hearts, of,...   \n",
       "4     [sir, paul, rocks, super, bowl, crowds, sir, p...   \n",
       "...                                                 ...   \n",
       "2995  [uk, directors, guild, nominees, named, martin...   \n",
       "2996  [u2, to, play, at, grammy, awards, show, irish...   \n",
       "2997  [pountney, handed, ban, and, fine, northampton...   \n",
       "2998  [belle, named, best, scottish, band, belle, &,...   \n",
       "2999  [criminal, probe, on, citigroup, deals, trader...   \n",
       "\n",
       "                                                  text2  \n",
       "0     gardener wins double in glasgow britain s jaso...  \n",
       "1     amnesty chief laments war failure the lack of ...  \n",
       "2     hanks greeted at wintry premiere hollywood sta...  \n",
       "3     redford s vision of sundance despite sporting ...  \n",
       "4     mauresmo opens with victory in la amelie maure...  \n",
       "...                                                 ...  \n",
       "2995  steel firm  to cut  45 000 jobs mittal steel  ...  \n",
       "2996  israel looks to us for bank chief israel has a...  \n",
       "2997  india and iran in gas export deal india has si...  \n",
       "2998  mido makes third apology ahmed  mido  hossam h...  \n",
       "2999  former ni minister scott dies former northern ...  \n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "df['text1'] = df['text1'].apply(word_tokenize)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[broadband, challenge, tv, viewing, the, numbe...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[rap, bos, arrested, over, drug, find, rap, mo...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[player, burn-out, worry, robinson, england, c...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[heart, of, oak, 3-2, cotonsport, heart, of, o...</td>\n",
       "      <td>redford s vision of sundance despite sporting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[sir, paul, rock, super, bowl, crowd, sir, pau...</td>\n",
       "      <td>mauresmo opens with victory in la amelie maure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>[uk, director, guild, nominee, named, martin, ...</td>\n",
       "      <td>steel firm  to cut  45 000 jobs mittal steel  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>[u2, to, play, at, grammy, award, show, irish,...</td>\n",
       "      <td>israel looks to us for bank chief israel has a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>[pountney, handed, ban, and, fine, northampton...</td>\n",
       "      <td>india and iran in gas export deal india has si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>[belle, named, best, scottish, band, belle, &amp;,...</td>\n",
       "      <td>mido makes third apology ahmed  mido  hossam h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>[criminal, probe, on, citigroup, deal, trader,...</td>\n",
       "      <td>former ni minister scott dies former northern ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text1  \\\n",
       "0     [broadband, challenge, tv, viewing, the, numbe...   \n",
       "1     [rap, bos, arrested, over, drug, find, rap, mo...   \n",
       "2     [player, burn-out, worry, robinson, england, c...   \n",
       "3     [heart, of, oak, 3-2, cotonsport, heart, of, o...   \n",
       "4     [sir, paul, rock, super, bowl, crowd, sir, pau...   \n",
       "...                                                 ...   \n",
       "2995  [uk, director, guild, nominee, named, martin, ...   \n",
       "2996  [u2, to, play, at, grammy, award, show, irish,...   \n",
       "2997  [pountney, handed, ban, and, fine, northampton...   \n",
       "2998  [belle, named, best, scottish, band, belle, &,...   \n",
       "2999  [criminal, probe, on, citigroup, deal, trader,...   \n",
       "\n",
       "                                                  text2  \n",
       "0     gardener wins double in glasgow britain s jaso...  \n",
       "1     amnesty chief laments war failure the lack of ...  \n",
       "2     hanks greeted at wintry premiere hollywood sta...  \n",
       "3     redford s vision of sundance despite sporting ...  \n",
       "4     mauresmo opens with victory in la amelie maure...  \n",
       "...                                                 ...  \n",
       "2995  steel firm  to cut  45 000 jobs mittal steel  ...  \n",
       "2996  israel looks to us for bank chief israel has a...  \n",
       "2997  india and iran in gas export deal india has si...  \n",
       "2998  mido makes third apology ahmed  mido  hossam h...  \n",
       "2999  former ni minister scott dies former northern ...  \n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = WordNetLemmatizer()\n",
    "df['text1']=df['text1'].apply(lambda row: [lm.lemmatize(word) for word in row])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing number europea...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested drug find rap mogul marion s...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn worries robinson england coach and...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  broadband challenges tv viewing number europea...   \n",
       "1  rap boss arrested drug find rap mogul marion s...   \n",
       "2  player burn worries robinson england coach and...   \n",
       "\n",
       "                                               text2  \n",
       "0  gardener wins double in glasgow britain s jaso...  \n",
       "1  amnesty chief laments war failure the lack of ...  \n",
       "2  hanks greeted at wintry premiere hollywood sta...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging preprocessed_text1 in text_data\n",
    "df['text1'] = preprocessed_text1\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [02:04<00:00, 24.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "preprocessed_text2 = []\n",
    "\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(df['text2'].values):\n",
    "    sent = decontract(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    \n",
    "   \n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords.words('english'))\n",
    "    preprocessed_text2.append(sent.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing number europea...</td>\n",
       "      <td>gardener wins double glasgow britain jason gar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested drug find rap mogul marion s...</td>\n",
       "      <td>amnesty chief laments war failure lack public ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn worries robinson england coach and...</td>\n",
       "      <td>hanks greeted wintry premiere hollywood star t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearts oak 3 2 cotonsport hearts oak set ghana...</td>\n",
       "      <td>redford vision sundance despite sporting cordu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
       "      <td>mauresmo opens victory la amelie mauresmo mari...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  broadband challenges tv viewing number europea...   \n",
       "1  rap boss arrested drug find rap mogul marion s...   \n",
       "2  player burn worries robinson england coach and...   \n",
       "3  hearts oak 3 2 cotonsport hearts oak set ghana...   \n",
       "4  sir paul rocks super bowl crowds sir paul mcca...   \n",
       "\n",
       "                                               text2  \n",
       "0  gardener wins double glasgow britain jason gar...  \n",
       "1  amnesty chief laments war failure lack public ...  \n",
       "2  hanks greeted wintry premiere hollywood star t...  \n",
       "3  redford vision sundance despite sporting cordu...  \n",
       "4  mauresmo opens victory la amelie mauresmo mari...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging preprocessed_text2 in text_data\n",
    "\n",
    "df['text2'] = preprocessed_text2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing number europea...</td>\n",
       "      <td>[gardener, win, double, glasgow, britain, jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested drug find rap mogul marion s...</td>\n",
       "      <td>[amnesty, chief, lament, war, failure, lack, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn worries robinson england coach and...</td>\n",
       "      <td>[hank, greeted, wintry, premiere, hollywood, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearts oak 3 2 cotonsport hearts oak set ghana...</td>\n",
       "      <td>[redford, vision, sundance, despite, sporting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
       "      <td>[mauresmo, open, victory, la, amelie, mauresmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>uk directors guild nominees named martin scors...</td>\n",
       "      <td>[steel, firm, cut, 45, 000, job, mittal, steel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>u2 play grammy awards show irish rock band u2 ...</td>\n",
       "      <td>[israel, look, u, bank, chief, israel, asked, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>pountney handed ban fine northampton coach bud...</td>\n",
       "      <td>[india, iran, gas, export, deal, india, signed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>belle named best scottish band belle sebastian...</td>\n",
       "      <td>[mido, make, third, apology, ahmed, mido, hoss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>criminal probe citigroup deals traders us bank...</td>\n",
       "      <td>[former, ni, minister, scott, dy, former, nort...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text1  \\\n",
       "0     broadband challenges tv viewing number europea...   \n",
       "1     rap boss arrested drug find rap mogul marion s...   \n",
       "2     player burn worries robinson england coach and...   \n",
       "3     hearts oak 3 2 cotonsport hearts oak set ghana...   \n",
       "4     sir paul rocks super bowl crowds sir paul mcca...   \n",
       "...                                                 ...   \n",
       "2995  uk directors guild nominees named martin scors...   \n",
       "2996  u2 play grammy awards show irish rock band u2 ...   \n",
       "2997  pountney handed ban fine northampton coach bud...   \n",
       "2998  belle named best scottish band belle sebastian...   \n",
       "2999  criminal probe citigroup deals traders us bank...   \n",
       "\n",
       "                                                  text2  \n",
       "0     [gardener, win, double, glasgow, britain, jaso...  \n",
       "1     [amnesty, chief, lament, war, failure, lack, p...  \n",
       "2     [hank, greeted, wintry, premiere, hollywood, s...  \n",
       "3     [redford, vision, sundance, despite, sporting,...  \n",
       "4     [mauresmo, open, victory, la, amelie, mauresmo...  \n",
       "...                                                 ...  \n",
       "2995  [steel, firm, cut, 45, 000, job, mittal, steel...  \n",
       "2996  [israel, look, u, bank, chief, israel, asked, ...  \n",
       "2997  [india, iran, gas, export, deal, india, signed...  \n",
       "2998  [mido, make, third, apology, ahmed, mido, hoss...  \n",
       "2999  [former, ni, minister, scott, dy, former, nort...  \n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text2'] = df['text2'].apply(word_tokenize)\n",
    "df['text2']=df['text2'].apply(lambda row: [lm.lemmatize(word) for word in row])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL APPROACH\n",
    "Word embeddings are low dimensional vectors obtained by training a neural network on a large corpus to predict a word given a context (Continuous Bag Of Words model) or to predict the context given a word (skip gram model). The context is a window of surrounding words. Pre-trained word embeddings are also available in the word2vec code.google page.\n",
    "\n",
    "In this i am using Google news pre trained vectors and compare similarity between text1 & text2 using n_similarity method in gensim library which is nothing compares cosine similarity between two\n",
    "\n",
    "Consider it as a unsupervised problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre_trained Google News Vectors after download file\n",
    "\n",
    "wordmodelfile=\"/Users/shabnam/Downloads/DataNeuron_DataScience_Task1/untitled folder/GoogleNews-vectors-negative300.bin\"\n",
    "wordmodel= gensim.models.KeyedVectors.load_word2vec_format(wordmodelfile, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6510956"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordmodel.similarity(\"king\",\"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7190052]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wordmodel['good'].reshape(1,-1),wordmodel['bad'].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list_text1 = df['text1'].to_list()\n",
    "final_list_text2 = df['text2'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vectorizer(list_of_docs,model):\n",
    "    \n",
    "    feature =[] # save rew vector \n",
    "    for rew in list_of_docs: # iterating over reviews\n",
    "        zero_vector = np.zeros(model.vector_size) # keyerror\n",
    "        vectors =[] # to append vector of each word\n",
    "        for word in rew : # iterating over all words in a review\n",
    "            if word in model: # checking if word is there in our vocab\n",
    "                try :\n",
    "                    vectors.append(model[word]) # appending vector of each word\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors: # if Vectors is a empty list or not \n",
    "            vectors = np.asarray(vectors) # converting multiple arrays into a single array\n",
    "            avg_vec = vectors.mean(axis=0) # avg of all vectors\n",
    "            feature.append(avg_vec) # appending the avg vector\n",
    "        else :\n",
    "            feature.append(zero_vector) # handling key error\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_text1 = vectorizer(final_list_text1,wordmodel)\n",
    "vector_text2 = vectorizer(final_list_text2,wordmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "similarity = []\n",
    "for i in range(len(vector_text1)):\n",
    "    text1 = vector_text1[i].reshape(1,-1)\n",
    "    text2 = vector_text2[i].reshape(1,-1)\n",
    "    score = cosine_similarity(text1,text2)[0][0]\n",
    "    similarity.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing number europea...</td>\n",
       "      <td>[gardener, win, double, glasgow, britain, jaso...</td>\n",
       "      <td>0.451430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested drug find rap mogul marion s...</td>\n",
       "      <td>[amnesty, chief, lament, war, failure, lack, p...</td>\n",
       "      <td>0.279069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn worries robinson england coach and...</td>\n",
       "      <td>[hank, greeted, wintry, premiere, hollywood, s...</td>\n",
       "      <td>0.371034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearts oak 3 2 cotonsport hearts oak set ghana...</td>\n",
       "      <td>[redford, vision, sundance, despite, sporting,...</td>\n",
       "      <td>0.295228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
       "      <td>[mauresmo, open, victory, la, amelie, mauresmo...</td>\n",
       "      <td>0.356393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>uk directors guild nominees named martin scors...</td>\n",
       "      <td>[steel, firm, cut, 45, 000, job, mittal, steel...</td>\n",
       "      <td>0.291368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>u2 play grammy awards show irish rock band u2 ...</td>\n",
       "      <td>[israel, look, u, bank, chief, israel, asked, ...</td>\n",
       "      <td>0.465628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>pountney handed ban fine northampton coach bud...</td>\n",
       "      <td>[india, iran, gas, export, deal, india, signed...</td>\n",
       "      <td>0.342331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>belle named best scottish band belle sebastian...</td>\n",
       "      <td>[mido, make, third, apology, ahmed, mido, hoss...</td>\n",
       "      <td>0.353406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>criminal probe citigroup deals traders us bank...</td>\n",
       "      <td>[former, ni, minister, scott, dy, former, nort...</td>\n",
       "      <td>0.407593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text1  \\\n",
       "0     broadband challenges tv viewing number europea...   \n",
       "1     rap boss arrested drug find rap mogul marion s...   \n",
       "2     player burn worries robinson england coach and...   \n",
       "3     hearts oak 3 2 cotonsport hearts oak set ghana...   \n",
       "4     sir paul rocks super bowl crowds sir paul mcca...   \n",
       "...                                                 ...   \n",
       "2995  uk directors guild nominees named martin scors...   \n",
       "2996  u2 play grammy awards show irish rock band u2 ...   \n",
       "2997  pountney handed ban fine northampton coach bud...   \n",
       "2998  belle named best scottish band belle sebastian...   \n",
       "2999  criminal probe citigroup deals traders us bank...   \n",
       "\n",
       "                                                  text2  similarity  \n",
       "0     [gardener, win, double, glasgow, britain, jaso...    0.451430  \n",
       "1     [amnesty, chief, lament, war, failure, lack, p...    0.279069  \n",
       "2     [hank, greeted, wintry, premiere, hollywood, s...    0.371034  \n",
       "3     [redford, vision, sundance, despite, sporting,...    0.295228  \n",
       "4     [mauresmo, open, victory, la, amelie, mauresmo...    0.356393  \n",
       "...                                                 ...         ...  \n",
       "2995  [steel, firm, cut, 45, 000, job, mittal, steel...    0.291368  \n",
       "2996  [israel, look, u, bank, chief, israel, asked, ...    0.465628  \n",
       "2997  [india, iran, gas, export, deal, india, signed...    0.342331  \n",
       "2998  [mido, make, third, apology, ahmed, mido, hoss...    0.353406  \n",
       "2999  [former, ni, minister, scott, dy, former, nort...    0.407593  \n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['similarity'] = similarity\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score.to_csv('final_score.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
